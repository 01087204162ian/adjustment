# app.py
import io
import numpy as np
import pandas as pd
import streamlit as st

ST_RATE_JACHA = 11.6
ST_RATE_NOJACHA = 9.02

st.set_page_config(page_title="ì‹œê°„ì œë³´í—˜ ì •ì‚°", layout="wide")
st.title("ì‹œê°„ì œë³´í—˜(ì‚¬ë¥œì°¨) ìš´í–‰ ë°ì´í„° ì •ì‚°")

st.markdown(
    """
- ì…ë ¥: Excel(xlsx)
- ê·œì¹™(í™•ì •): Iì—´ ë‹´ë³´ = `jacha(ìì°¨í¬í•¨)`, `nojacha(ìì°¨ë¯¸í¬í•¨)` / **Lì—´ ìƒíƒœ `'ì •ìƒ'`ë§Œ ì •ì‚°**
- ì¶œë ¥: `ì •ì‚°_ìš”ì•½(ì¼ì)`, `ì¤‘ë³µ_ìƒì„¸(ê¸°ì‚¬)`, `ì˜¤ë¥˜_ë¦¬í¬íŠ¸`
"""
)

rounding_mode = st.selectbox(
    "ë³´í—˜ë£Œ ì› ë‹¨ìœ„ ì²˜ë¦¬",
    options=["ë°˜ì˜¬ë¦¼(round)", "ë²„ë¦¼(floor)", "ì˜¬ë¦¼(ceil)"],
    index=0,
)

uploaded = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"])


def make_datetimes_excel_safe(df: pd.DataFrame) -> pd.DataFrame:
    """Excelì€ tz-aware datetimeì„ ì €ì¥ ëª»í•˜ë¯€ë¡œ tz ì •ë³´ë¥¼ ì œê±°(naiveë¡œ ë³€í™˜)"""
    df2 = df.copy()
    for c in df2.columns:
        if pd.api.types.is_datetime64tz_dtype(df2[c]):
            df2[c] = df2[c].dt.tz_localize(None)
    return df2


def _to_dt(series: pd.Series, col_name: str, errors: list) -> pd.Series:
    dt = pd.to_datetime(series, errors="coerce")
    bad = dt.isna() & series.notna() & (series.astype(str).str.strip() != "")
    if bad.any():
        for idx in series[bad].index[:2000]:
            errors.append(
                {
                    "row_index": int(idx) + 2,
                    "type": "time_parse_fail",
                    "col": col_name,
                    "value": str(series.loc[idx]),
                }
            )
    return dt


def _ceil_minutes(delta_seconds: pd.Series) -> pd.Series:
    """
    ceil(seconds/60) with NaN preserved (SAFE):
    pd.NA(NAType) -> NaNìœ¼ë¡œ ê°•ì œ ë³€í™˜ í›„ numpy ì²˜ë¦¬
    """
    sec = pd.to_numeric(delta_seconds, errors="coerce").to_numpy(dtype="float64")
    out = np.full(sec.shape, np.nan, dtype="float64")
    mask = ~np.isnan(sec)
    out[mask] = np.ceil(sec[mask] / 60.0)
    return pd.Series(out, index=delta_seconds.index).astype("Int64")


def _apply_rounding_vectorized(series: pd.Series) -> pd.Series:
    """
    Vectorized rounding (SAFE):
    pd.NA(NAType) -> NaNìœ¼ë¡œ ê°•ì œ ë³€í™˜ í›„ numpy ì²˜ë¦¬
    """
    arr = pd.to_numeric(series, errors="coerce").to_numpy(dtype="float64")
    out = np.zeros(arr.shape, dtype="int64")
    mask = ~np.isnan(arr)

    if rounding_mode.startswith("ë°˜ì˜¬ë¦¼"):
        out[mask] = np.rint(arr[mask]).astype("int64")
    elif rounding_mode.startswith("ë²„ë¦¼"):
        out[mask] = np.floor(arr[mask]).astype("int64")
    else:  # ì˜¬ë¦¼
        out[mask] = np.ceil(arr[mask]).astype("int64")

    return pd.Series(out, index=series.index)


def process(df: pd.DataFrame, status=None):
    if status:
        status.update(label="1) íŒŒì¼ ì½ê¸° ì™„ë£Œ", state="running")

    errors = []

    needed_positions = {"D": 3, "F": 5, "G": 6, "H": 7, "I": 8, "L": 11, "N": 13}
    max_pos = max(needed_positions.values())
    if df.shape[1] <= max_pos:
        raise ValueError(
            f"í•„ìš” ì—´ ìœ„ì¹˜ê¹Œì§€ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼ ìˆ˜={df.shape[1]}, í•„ìš” ìµœì†Œ={max_pos+1}"
        )

    col_D = df.columns[needed_positions["D"]]
    col_F = df.columns[needed_positions["F"]]
    col_G = df.columns[needed_positions["G"]]
    col_H = df.columns[needed_positions["H"]]
    col_I = df.columns[needed_positions["I"]]
    col_L = df.columns[needed_positions["L"]]
    col_N = df.columns[needed_positions["N"]]

    # Parse times
    if status:
        status.update(label="2) ì‹œê°„ íŒŒì‹± ì¤‘...", state="running")
    df["_start_dt"] = _to_dt(df[col_F], "F(start)", errors)
    df["_end_dt"] = _to_dt(df[col_G], "G(end)", errors)

    # End < start
    bad_order = (
        df["_start_dt"].notna()
        & df["_end_dt"].notna()
        & (df["_end_dt"] < df["_start_dt"])
    )
    if bad_order.any():
        for idx in df[bad_order].index[:2000]:
            errors.append(
                {
                    "row_index": int(idx) + 2,
                    "type": "end_before_start",
                    "col": "F/G",
                    "value": f"start={df.loc[idx,'_start_dt']}, end={df.loc[idx,'_end_dt']}",
                }
            )

    # duration seconds
    df["_dur_sec"] = (df["_end_dt"] - df["_start_dt"]).dt.total_seconds()
    df.loc[bad_order, "_dur_sec"] = np.nan

    # H recompute: ceil minutes
    if status:
        status.update(label="3) ìš´í–‰ì‹œê°„(ë¶„) ê³„ì‚° ì¤‘...", state="running")
    df[col_H] = _ceil_minutes(df["_dur_sec"])

    # L status normalize - 'ì •ìƒ'ë§Œ ì •ì‚° í¬í•¨
    if status:
        status.update(label="4) ì •ì‚° ì œì™¸ ì²˜ë¦¬ ì¤‘...", state="running")
    status_str = df[col_L].fillna("").astype(str).str.strip()
    include_mask = status_str == "ì •ìƒ"
    exclude = ~include_mask
    df.loc[exclude, col_H] = pd.NA

    # N = date(start)
    df[col_N] = df["_start_dt"].dt.strftime("%Y-%m-%d")

    # I ë‹´ë³´ normalize (ê³µë°±ë¥˜ ì œê±°ê¹Œì§€ ì•ˆì „í•˜ê²Œ)
    df["_cover"] = (
        df[col_I]
        .fillna("")
        .astype(str)
        .str.lower()
        .str.replace(r"\s+", "", regex=True)
    )
    valid_cover = df["_cover"].isin(["jacha", "nojacha"])
    if (~valid_cover & df[col_I].notna()).any():
        for idx in df[(~valid_cover) & df[col_I].notna()].index[:2000]:
            errors.append(
                {
                    "row_index": int(idx) + 2,
                    "type": "invalid_cover",
                    "col": "I(ë‹´ë³´)",
                    "value": str(df.loc[idx, col_I]),
                }
            )
    df.loc[~valid_cover, "_cover"] = pd.NA

    # Only rows with valid H and valid cover participate in summaries
    df["_ok"] = (
        df[col_H].notna()
        & df["_cover"].notna()
        & df[col_N].notna()
        & df[col_D].notna()
    )

    # -------- Overlap detection (per D+N) --------
    if status:
        status.update(label="5) ì¤‘ë³µ ìš´í–‰ ê³„ì‚° ì¤‘...", state="running")
    work = df[df["_ok"]].copy()
    work["_driver"] = work[col_D].astype(str)
    work["_date"] = work[col_N].astype(str)

    work = work.sort_values(by=["_driver", "_date", "_start_dt"], kind="mergesort")

    # prev end/start
    work["_prev_end"] = work.groupby(["_driver", "_date"])["_end_dt"].shift(1)
    work["_prev_start"] = work.groupby(["_driver", "_date"])["_start_dt"].shift(1)

    overlap_mask = work["_prev_end"].notna() & (work["_prev_end"] > work["_start_dt"])
    work["_overlap_sec"] = np.nan
    work.loc[overlap_mask, "_overlap_sec"] = (
        work.loc[overlap_mask, "_prev_end"] - work.loc[overlap_mask, "_start_dt"]
    ).dt.total_seconds()

    work["_overlap_min"] = _ceil_minutes(work["_overlap_sec"])

    # Assign overlap to "next row's cover" (this row's cover)
    work["_overlap_jacha"] = 0
    work["_overlap_nojacha"] = 0
    jmask = overlap_mask & (work["_cover"] == "jacha")
    nmask = overlap_mask & (work["_cover"] == "nojacha")
    work.loc[jmask, "_overlap_jacha"] = work.loc[jmask, "_overlap_min"].fillna(0).astype(int)
    work.loc[nmask, "_overlap_nojacha"] = work.loc[nmask, "_overlap_min"].fillna(0).astype(int)

    # Overlap detail sheet
    overlap_detail = work.loc[
        overlap_mask,
        ["_driver", "_date", "_prev_start", "_prev_end", "_start_dt", "_end_dt", "_cover", "_overlap_min"],
    ].rename(
        columns={
            "_driver": "ê¸°ì‚¬ID(D)",
            "_date": "ê¸°ì¤€ì˜ì—…ì¼(N)",
            "_prev_start": "ì´ì „ ì‹œì‘",
            "_prev_end": "ì´ì „ ì¢…ë£Œ",
            "_start_dt": "ë‹¤ìŒ ì‹œì‘",
            "_end_dt": "ë‹¤ìŒ ì¢…ë£Œ",
            "_cover": "ë‹¤ìŒ ë‹´ë³´(I)",
            "_overlap_min": "ì¤‘ë³µì‹œê°„(ë¶„)",
        }
    )

    # Daily sums for run minutes by cover
    work["_run_jacha"] = 0
    work["_run_nojacha"] = 0
    work.loc[work["_cover"] == "jacha", "_run_jacha"] = work.loc[work["_cover"] == "jacha", col_H].astype(int)
    work.loc[work["_cover"] == "nojacha", "_run_nojacha"] = work.loc[work["_cover"] == "nojacha", col_H].astype(int)

    daily = (
        work.groupby(["_date"], as_index=False)
        .agg(
            **{
                "ìš´í–‰(ë¶„)_ìì°¨í¬í•¨": ("_run_jacha", "sum"),
                "ìš´í–‰(ë¶„)_ìì°¨ë¯¸í¬í•¨": ("_run_nojacha", "sum"),
                "ì¤‘ë³µìš´í–‰(ë¶„)_ìì°¨í¬í•¨": ("_overlap_jacha", "sum"),
                "ì¤‘ë³µìš´í–‰(ë¶„)_ìì°¨ë¯¸í¬í•¨": ("_overlap_nojacha", "sum"),
            }
        )
        .rename(columns={"_date": "ìš´í–‰ì¼"})
    )

    daily["ì •ì‚° ìš´í–‰(ë¶„)_ìì°¨í¬í•¨"] = daily["ìš´í–‰(ë¶„)_ìì°¨í¬í•¨"] - daily["ì¤‘ë³µìš´í–‰(ë¶„)_ìì°¨í¬í•¨"]
    daily["ì •ì‚° ìš´í–‰(ë¶„)_ìì°¨ë¯¸í¬í•¨"] = daily["ìš´í–‰(ë¶„)_ìì°¨ë¯¸í¬í•¨"] - daily["ì¤‘ë³µìš´í–‰(ë¶„)_ìì°¨ë¯¸í¬í•¨"]

    # ë³´í—˜ë£Œ
    daily["ë¶„ë‹¹ë‹¨ê°€_ìì°¨í¬í•¨"] = ST_RATE_JACHA
    daily["ë¶„ë‹¹ë‹¨ê°€_ìì°¨ë¯¸í¬í•¨"] = ST_RATE_NOJACHA

    if status:
        status.update(label="6) ë³´í—˜ë£Œ ì‚°ì¶œ ì¤‘...", state="running")
    daily["ë³´í—˜ë£Œ_ìì°¨í¬í•¨"] = _apply_rounding_vectorized(daily["ì •ì‚° ìš´í–‰(ë¶„)_ìì°¨í¬í•¨"] * ST_RATE_JACHA)
    daily["ë³´í—˜ë£Œ_ìì°¨ë¯¸í¬í•¨"] = _apply_rounding_vectorized(daily["ì •ì‚° ìš´í–‰(ë¶„)_ìì°¨ë¯¸í¬í•¨"] * ST_RATE_NOJACHA)
    daily["ì¼ì ì´ë³´í—˜ë£Œ"] = daily["ë³´í—˜ë£Œ_ìì°¨í¬í•¨"] + daily["ë³´í—˜ë£Œ_ìì°¨ë¯¸í¬í•¨"]

    # Error report
    err_df = pd.DataFrame(errors)
    if err_df.empty:
        err_df = pd.DataFrame([{"type": "none", "message": "ì˜¤ë¥˜ ì—†ìŒ"}])

    # Debug
    debug_info = {
        "ì´_í–‰ìˆ˜": len(df),
        "start_dt_notna": int(df["_start_dt"].notna().sum()),
        "end_dt_notna": int(df["_end_dt"].notna().sum()),
        "H_notna": int(df[col_H].notna().sum()),
        "cover_valid": int(df["_cover"].notna().sum()),
        "N_notna": int(df[col_N].notna().sum()),
        "ok_rows": int(df["_ok"].sum()),
        "ì •ì‚°_í¬í•¨_í–‰ìˆ˜(L=ì •ìƒ)": int(include_mask.sum()),
        "ì •ì‚°_ì œì™¸_í–‰ìˆ˜": int(exclude.sum()),
    }

    return daily, overlap_detail, err_df, debug_info, status_str


if uploaded:
    try:
        in_bytes = uploaded.read()
        df0 = pd.read_excel(io.BytesIO(in_bytes), engine="openpyxl")
        st.write(f"ë¡œë“œ ì™„ë£Œ: {df0.shape[0]:,} rows Ã— {df0.shape[1]:,} cols")

        if st.button("ì •ì‚° ì‹¤í–‰(ìš”ì•½/ì¤‘ë³µ/ì˜¤ë¥˜ ìƒì„±)", type="primary"):
            with st.status("ì •ì‚° ì²˜ë¦¬ ì¤‘...", expanded=True) as status:
                status.update(label="ì²˜ë¦¬ ì‹œì‘...", state="running")
                daily, overlap_detail, err_df, debug_info, status_str = process(df0, status=status)
                status.update(label="ê²°ê³¼ ìƒì„± ì™„ë£Œ!", state="complete")

            st.subheader("ğŸ” ë””ë²„ê·¸ ì •ë³´")
            col1, col2 = st.columns(2)
            with col1:
                st.write("**DEBUG COUNTS:**")
                st.json(debug_info)
            with col2:
                st.write("**Lì—´ ìƒíƒœê°’ ë¶„í¬ (ìƒìœ„ 10):**")
                st.dataframe(status_str.value_counts(dropna=False).head(10))

            st.subheader("ì •ì‚°_ìš”ì•½(ì¼ì)")
            st.dataframe(daily, use_container_width=True)

            st.subheader("ì¤‘ë³µ_ìƒì„¸(ê¸°ì‚¬) (ìƒìœ„ 200ê±´)")
            st.dataframe(overlap_detail.head(200), use_container_width=True)

            st.subheader("ì˜¤ë¥˜_ë¦¬í¬íŠ¸ (ìƒìœ„ 200ê±´)")
            st.dataframe(err_df.head(200), use_container_width=True)

            out = io.BytesIO()

            # Excel ì €ì¥ ì „ timezone ì œê±° (í•µì‹¬ íŒ¨ì¹˜)
            daily_x = make_datetimes_excel_safe(daily)
            overlap_x = make_datetimes_excel_safe(overlap_detail)
            err_x = make_datetimes_excel_safe(err_df)

            with pd.ExcelWriter(out, engine="openpyxl") as writer:
                daily_x.to_excel(writer, index=False, sheet_name="ì •ì‚°_ìš”ì•½(ì¼ì)")
                overlap_x.to_excel(writer, index=False, sheet_name="ì¤‘ë³µ_ìƒì„¸(ê¸°ì‚¬)")
                err_x.to_excel(writer, index=False, sheet_name="ì˜¤ë¥˜_ë¦¬í¬íŠ¸")
            out.seek(0)

            st.download_button(
                "ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=out,
                file_name="ì •ì‚°_ê²°ê³¼.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

    except Exception as e:
        st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
else:
    st.info("ì¢Œì¸¡ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
